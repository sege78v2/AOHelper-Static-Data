name: Update AOHelper static data daily

on:
  workflow_dispatch:
  schedule:
    - cron: "10 3 * * *" # daily 03:10 UTC (~06:10 TR)

permissions:
  contents: write

jobs:
  update:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Build items + i18n split + markets + manifest (manifest-only)
        shell: bash
        run: |
          set -euo pipefail

          mkdir -p data data/i18n

          #####################################
          # 0) CLEAN LEGACY (no manual delete)
          #####################################
          rm -f \
            data/items.meta.json \
            data/items.i18n.json \
            data/items.i18n.meta.json \
            data/i18n.upstream.meta.json

          #####################################
          # 1) ITEM IDS (items.json ONLY)
          #####################################
          SRC_ITEMS_TXT="https://raw.githubusercontent.com/ao-data/ao-bin-dumps/master/formatted/items.txt"
          curl -fsSL "$SRC_ITEMS_TXT" -o data/items.txt.new

          python3 - <<'PY'
          import json, datetime

          src_url = "https://raw.githubusercontent.com/ao-data/ao-bin-dumps/master/formatted/items.txt"
          path = "data/items.txt.new"

          raw = open(path, "rb").read()
          lines = raw.decode("utf-8", errors="replace").splitlines()

          now = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

          item_ids = []
          for line in lines:
              line = line.strip()
              if not line:
                  continue
              parts = line.split()
              if len(parts) >= 2 and parts[0].endswith(":") and parts[0][:-1].isdigit():
                  item_ids.append(parts[1])
              else:
                  item_ids.append(parts[0])

          with open("data/items.json", "w", encoding="utf-8") as f:
              json.dump(
                  {"generatedAt": now, "source": src_url, "count": len(item_ids), "items": item_ids},
                  f,
                  ensure_ascii=False,
                  separators=(",", ":"),
              )
          PY

          rm -f data/items.txt.new

          #####################################
          # 2) I18N SPLIT (15 languages)
          #####################################
          SRC_ITEMS_FULL_JSON="https://raw.githubusercontent.com/ao-data/ao-bin-dumps/master/formatted/items.json"
          curl -fsSL "$SRC_ITEMS_FULL_JSON" -o data/items.full.json.new

          python3 - <<'PY'
          import json, datetime, os

          src_url = "https://raw.githubusercontent.com/ao-data/ao-bin-dumps/master/formatted/items.json"
          path = "data/items.full.json.new"

          raw = open(path, "rb").read()
          arr = json.loads(raw.decode("utf-8", errors="replace"))

          now = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

          langs = [
              "EN-US","DE-DE","FR-FR","RU-RU","PL-PL","ES-ES","PT-BR","IT-IT",
              "ZH-CN","KO-KR","JA-JP","ZH-TW","ID-ID","TR-TR","AR-SA"
          ]

          os.makedirs("data/i18n", exist_ok=True)

          for lang in langs:
              out = {}
              for it in arr:
                  uid = it.get("UniqueName")
                  if not uid:
                      continue
                  names = it.get("LocalizedNames") or {}
                  descs = it.get("LocalizedDescriptions") or {}
                  n = names.get(lang)
                  d = descs.get(lang)
                  if n is None and d is None:
                      continue
                  out[uid] = {"name": n, "desc": d}

              payload = {"generatedAt": now, "source": src_url, "lang": lang, "count": len(out), "items": out}
              b = json.dumps(payload, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
              with open(f"data/i18n/{lang}.json", "wb") as f:
                  f.write(b)
          PY

          rm -f data/items.full.json.new

          #####################################
          # 3) MARKETS (markets.json)
          #####################################
          SRC_WORLD_TXT="https://raw.githubusercontent.com/ao-data/ao-bin-dumps/master/formatted/world.txt"
          curl -fsSL "$SRC_WORLD_TXT" -o data/world.txt.new

          python3 - <<'PY'
          import re, json, datetime

          src_url = "https://raw.githubusercontent.com/ao-data/ao-bin-dumps/master/formatted/world.txt"
          path = "data/world.txt.new"
          text = open(path, "r", encoding="utf-8", errors="replace").read().splitlines()

          now = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

          # Baseline known markets (stable). We also try to auto-pick any line containing "Market".
          known = {
              "Bridgewatch","Martlock","Thetford","Fort Sterling","Lymhurst","Caerleon","Brecilien","Black Market"
          }

          found = set()

          for line in text:
              line = line.strip()
              if not line:
                  continue
              # Common dump format: "1234: Something With Spaces ..."
              m = re.match(r"^\s*\d+:\s*(.+?)\s*$", line)
              if not m:
                  continue
              name = m.group(1).strip()

              # Keep known markets, and any future entries that explicitly contain "Market"
              if name in known or "Market" in name:
                  found.add(name)

          # Ensure baseline always included
          found |= known

          markets = sorted(found)

          with open("data/markets.json", "w", encoding="utf-8") as f:
              json.dump(
                  {"generatedAt": now, "source": src_url, "count": len(markets), "markets": markets},
                  f,
                  ensure_ascii=False,
                  separators=(",", ":"),
              )
          PY

          rm -f data/world.txt.new

          #####################################
          # 4) MANIFEST (single source of truth)
          #####################################
          python3 - <<'PY'
          import os, json, hashlib, datetime

          def sha256_file(p: str) -> str:
              h = hashlib.sha256()
              with open(p, "rb") as f:
                  for chunk in iter(lambda: f.read(1024 * 1024), b""):
                      h.update(chunk)
              return h.hexdigest()

          def file_entry(p: str) -> dict:
              return {"url": "/" + p.replace("\\", "/"), "bytes": os.path.getsize(p), "sha256": sha256_file(p)}

          now = datetime.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

          langs = [
              "EN-US","DE-DE","FR-FR","RU-RU","PL-PL","ES-ES","PT-BR","IT-IT",
              "ZH-CN","KO-KR","JA-JP","ZH-TW","ID-ID","TR-TR","AR-SA"
          ]

          manifest = {
              "generatedAt": now,
              "version": 1,
              "files": {
                  "items": file_entry("data/items.json"),
                  "markets": file_entry("data/markets.json"),
                  "i18n": { lang: file_entry(f"data/i18n/{lang}.json") for lang in langs }
              }
          }

          with open("data/manifest.json", "w", encoding="utf-8") as f:
              json.dump(manifest, f, ensure_ascii=False, separators=(",", ":"))
          PY

          #####################################
          # Commit guard
          #####################################
          if git diff --quiet; then
            echo "No changes."
            exit 0
          fi

      - name: Commit & push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A data
          git commit -m "chore: daily data update"
          git push
